{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnysavita10/Generative-AI-Indepth-Basic-to-Advance/blob/main/ConversationEntityMemory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyfXAUX9tt5C"
      },
      "source": [
        "#### ConversationEntityMemory is a memory class provided by LangChain, designed to track and store information about entities that arise in a conversation. It allows the AI to \"remember\" key facts about people, places, or concepts mentioned during a conversation, so it can refer back to them later on, improving the conversational experience.\n",
        "\n",
        "## Key Features:\n",
        "**Entity Tracking:** It identifies entities (e.g., names, places, concepts) and stores relevant information about them. For instance, if you mention \"Tanmay\" in one part of a conversation, it can remember details about \"Tanmay\" for later reference.\n",
        "\n",
        "**Context-Aware:** It helps the AI maintain context by remembering details about the entities mentioned during the chat, ensuring more natural, fluid conversations over time.\n",
        "\n",
        "**Customization:** You can customize what to store and how to retrieve it during future interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KJkL7-belXEJ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yEZcG8GmlX7q"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JrcW8y-Lxcrz"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UHzW2v8qlUiB"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\",convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfmpxyFqld-k",
        "outputId": "a45e0a86-a1ff-4d57-f984-253380cbf840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "print(model.invoke(\"hi\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6oP8kSH7xZ00"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y_z9GNKik5Di"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SURESH BEEKHANI\\AppData\\Local\\Temp\\ipykernel_3844\\1182818481.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationEntityMemory(llm=model)\n",
            "c:\\conda_envs\\agent\\lib\\site-packages\\pydantic\\main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationEntityMemory(llm=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9lOMUwIlMcJ",
        "outputId": "1083435f-63f9-4165-dc91-844960a14f42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {}}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"i am very hungry.\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8qru5UcrgeC",
        "outputId": "d49fbd15-086a-4a41-9821-7d3617b735d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {'Suresh': '', 'Mayank': ''}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"Suresh  & mayank are working on a hackathon project\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGPOpmFesoC7",
        "outputId": "35a4434a-142f-4989-c4c7-1088f881fa18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {'John': '', 'Karachi': ''}}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"My name is John, and I'm planning a trip to karachi.\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6AwIuiDtBiy",
        "outputId": "a26fe41c-3a43-4f54-c0e1-9c57f3c40ed6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {'SURESH': ''}}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"SURESH is a great person who values gratitude.\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "F8EExXXblzaL"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"Human\": \"SURESH And Mayank are working on a hackathon project\"},\n",
        "    {\"AI\": \"That's awesome! What's the hackathon project about?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnwhQHgEuYeS",
        "outputId": "d8228df2-e284-4767-eb97-f1035053aeb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: SURESH And Mayank are working on a hackathon project\\nAI: That's awesome! What's the hackathon project about?\",\n",
              " 'entities': {}}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": \"who is Sunny?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wVGC3O-Vmofz"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"Human\": \"It's a machine learning project focused on healthcare.\"},\n",
        "     {\"AI\": \"Sounds exciting! Are they building a prediction model or something else?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "g84umam_1MX6"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"Human\": \"Yes, they are building prediction model.\"},\n",
        "    {\"AI\": \"Wishing Suresh and Mayank all the best for their project!\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkaw4hMX1loT",
        "outputId": "5530adea-9863-4633-ba96-d4c948296474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: SURESH And Mayank are working on a hackathon project\\nAI: That's awesome! What's the hackathon project about?\\nHuman: It's a machine learning project focused on healthcare.\\nAI: Sounds exciting! Are they building a prediction model or something else?\\nHuman: Yes, they are building prediction model.\\nAI: Wishing Suresh and Mayank all the best for their project!\",\n",
              " 'entities': {'SURESH': 'SURESH is working on a hackathon project with Mayank.'}}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": \"who is SURESH?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k62uDbQc17Ba",
        "outputId": "c473eb7c-644e-4071-f098-22ea9ca0ba2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update the summary of the provided entity in the \"Entity\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\n",
            "The update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\n",
            "\n",
            "If there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), return the existing summary unchanged.\n",
            "\n",
            "Full conversation history (for context):\n",
            "{history}\n",
            "\n",
            "Entity to summarize:\n",
            "{entity}\n",
            "\n",
            "Existing summary of {entity}:\n",
            "{summary}\n",
            "\n",
            "Last line of conversation:\n",
            "Human: {input}\n",
            "Updated summary:\n"
          ]
        }
      ],
      "source": [
        "print('You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update the summary of the provided entity in the \"Entity\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), return the existing summary unchanged.\\n\\nFull conversation history (for context):\\n{history}\\n\\nEntity to summarize:\\n{entity}\\n\\nExisting summary of {entity}:\\n{summary}\\n\\nLast line of conversation:\\nHuman: {input}\\nUpdated summary:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck2xTr9H26O7",
        "outputId": "18282a75-c119-46c8-a165-f2b1d899a93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\n",
            "\n",
            "The conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\n",
            "\n",
            "Return the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\n",
            "\n",
            "EXAMPLE\n",
            "Conversation history:\n",
            "Person #1: how's it going today?\n",
            "AI: \"It's going great! How about you?\"\n",
            "Person #1: good! busy working on Langchain. lots to do.\n",
            "AI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\n",
            "Last line:\n",
            "Person #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\n",
            "Output: Langchain\n",
            "END OF EXAMPLE\n",
            "\n",
            "EXAMPLE\n",
            "Conversation history:\n",
            "Person #1: how's it going today?\n",
            "AI: \"It's going great! How about you?\"\n",
            "Person #1: good! busy working on Langchain. lots to do.\n",
            "AI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\n",
            "Last line:\n",
            "Person #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\n",
            "Output: Langchain, Person #2\n",
            "END OF EXAMPLE\n",
            "\n",
            "Conversation history (for reference only):\n",
            "{history}\n",
            "Last line of conversation (for extraction):\n",
            "Human: {input}\n",
            "\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "print('You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I\\'m working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "P291dMnv3MlT"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "20gCJ34f4F-i"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5n-02nGT4HKy"
      },
      "outputs": [],
      "source": [
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_hUoV7Jt4Iry"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tRO6ucqk4Lsi"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooyiYhho4NVT",
        "outputId": "c9041a75-2fba-465a-892a-977f236aa696"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=model,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=model)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "lX97yNGp4cJz",
        "outputId": "4112c2de-cc7d-4f61-c61f-39dbef869a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Deven': '', 'Sam': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Last line:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"That's great! Hackathons are a great way to learn new skills, collaborate with others, and build innovative projects. What kind of project are they working on?\""
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Deven & Sam are working on a hackathon project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIQAi2Dh4qI0",
        "outputId": "545a45c1-3d10-49aa-eeed-8bbb9f578b18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Deven': 'Deven is working on a hackathon project with Sam.',\n",
              " 'Sam': 'Sam is currently working on a hackathon project with Deven.'}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.entity_store.store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Ik-bPxX34u4i",
        "outputId": "e450b4a6-769c-4831-b777-6f2738d2efd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Langchain': 'Langchain is a powerful tool whose capabilities could be expanded by adding more complex memory structures.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: That's great! Hackathons are a great way to learn new skills, collaborate with others, and build innovative projects. What kind of project are they working on?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds very interesting! Langchain is a very powerful tool, and adding more complex memory structures could greatly expand its capabilities. What kind of memory structures are they considering adding?\n",
            "Last line:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'That sounds very interesting! Langchain is a very powerful tool, and adding more complex memory structures could greatly expand its capabilities. What kind of memory structures are they considering adding?'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are trying to add more complex memory structures to Langchain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "ACakaFY64y_q",
        "outputId": "dad76347-c45d-43ca-9520-c29189c86ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: That's great! Hackathons are a great way to learn new skills, collaborate with others, and build innovative projects. What kind of project are they working on?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds very interesting! Langchain is a very powerful tool, and adding more complex memory structures could greatly expand its capabilities. What kind of memory structures are they considering adding?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds very interesting! Langchain is a very powerful tool, and adding more complex memory structures could greatly expand its capabilities. What kind of memory structures are they considering adding?\n",
            "Last line:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"That's a great idea! A key-value store would allow Langchain to store and retrieve information about entities in a structured and efficient way. This could be very useful for a variety of tasks, such as tracking the state of objects in a game or managing the inventory of a store.\\n\\nI'm curious to see how they implement the key-value store and how it will integrate with the rest of Langchain. It sounds like a very promising project, and I'm excited to see what they come up with.\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are adding in a key-value store for entities mentioned so far in the conversation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "VUfQMU365GtL",
        "outputId": "465becdd-d918-4dc7-f0d1-61b37e56f29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam.', 'Sam': 'Sam is currently working on a hackathon project with Deven.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds very interesting! Langchain is a very powerful tool, and adding more complex memory structures could greatly expand its capabilities. What kind of memory structures are they considering adding?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds very interesting! Langchain is a very powerful tool, and adding more complex memory structures could greatly expand its capabilities. What kind of memory structures are they considering adding?\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great idea! A key-value store would allow Langchain to store and retrieve information about entities in a structured and efficient way. This could be very useful for a variety of tasks, such as tracking the state of objects in a game or managing the inventory of a store.\n",
            "\n",
            "I'm curious to see how they implement the key-value store and how it will integrate with the rest of Langchain. It sounds like a very promising project, and I'm excited to see what they come up with.\n",
            "Last line:\n",
            "Human: What do you know about Deven & Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the information you have provided, I know that Deven and Sam are currently working together on a hackathon project. They are trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned in the conversation. This suggests that they are interested in using Langchain to build applications that require structured and efficient storage and retrieval of information.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Deven & Sam?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIFsSUtn5KGa",
        "outputId": "6849a1de-34f0-4743-b644-bf9912a1f7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Deven': 'Deven is working on a hackathon project with Sam, where they are '\n",
            "          'trying to add more complex memory structures to Langchain, '\n",
            "          'including a key-value store for entities mentioned in the '\n",
            "          'conversation.',\n",
            " 'Langchain': 'Langchain is a powerful tool whose capabilities could be '\n",
            "              'expanded by adding more complex memory structures, such as the '\n",
            "              'ones Deven and Sam are currently working on.',\n",
            " 'Sam': 'Sam is currently working on a hackathon project with Deven, and they '\n",
            "        'are interested in using Langchain to build applications that require '\n",
            "        'structured and efficient storage and retrieval of information.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "OVgc65P25ZpC",
        "outputId": "04e79e8d-1e04-430b-d020-3eb39fe564ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Daimon': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds very interesting! Langchain is a very powerful tool, and adding more complex memory structures could greatly expand its capabilities. What kind of memory structures are they considering adding?\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great idea! A key-value store would allow Langchain to store and retrieve information about entities in a structured and efficient way. This could be very useful for a variety of tasks, such as tracking the state of objects in a game or managing the inventory of a store.\n",
            "\n",
            "I'm curious to see how they implement the key-value store and how it will integrate with the rest of Langchain. It sounds like a very promising project, and I'm excited to see what they come up with.\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI: Based on the information you have provided, I know that Deven and Sam are currently working together on a hackathon project. They are trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned in the conversation. This suggests that they are interested in using Langchain to build applications that require structured and efficient storage and retrieval of information.\n",
            "Last line:\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"That's very interesting! I'm not familiar with Daimon, but I'm always interested in learning about new companies. What does Daimon do?\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Sam is the founder of a company called Daimon.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0MZLauH58Ra",
        "outputId": "5a259648-7ece-42bd-c85c-b4aeccc991d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Daimon': 'Daimon is a company founded by Sam.',\n",
            " 'Deven': 'Deven is working on a hackathon project with Sam, where they are '\n",
            "          'trying to add more complex memory structures to Langchain, '\n",
            "          'including a key-value store for entities mentioned in the '\n",
            "          'conversation.',\n",
            " 'Langchain': 'Langchain is a powerful tool whose capabilities could be '\n",
            "              'expanded by adding more complex memory structures, such as the '\n",
            "              'ones Deven and Sam are currently working on.',\n",
            " 'Sam': 'Sam is currently working on a hackathon project with Deven, and they '\n",
            "        'are interested in using Langchain to build applications that require '\n",
            "        'structured and efficient storage and retrieval of information.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "lTsnRFsh6EG6",
        "outputId": "c249efdf-1299-4e31-a8ba-73af3ef89dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great idea! A key-value store would allow Langchain to store and retrieve information about entities in a structured and efficient way. This could be very useful for a variety of tasks, such as tracking the state of objects in a game or managing the inventory of a store.\n",
            "\n",
            "I'm curious to see how they implement the key-value store and how it will integrate with the rest of Langchain. It sounds like a very promising project, and I'm excited to see what they come up with.\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI: Based on the information you have provided, I know that Deven and Sam are currently working together on a hackathon project. They are trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned in the conversation. This suggests that they are interested in using Langchain to build applications that require structured and efficient storage and retrieval of information.\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI: That's very interesting! I'm not familiar with Daimon, but I'm always interested in learning about new companies. What does Daimon do?\n",
            "Last line:\n",
            "Human: What do you know about Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Based on the information you have provided, I know that Sam is currently working on a hackathon project with Deven. They are trying to add more complex memory structures to Langchain, including a key-value store for entities mentioned in the conversation. This suggests that Sam is interested in using Langchain to build applications that require structured and efficient storage and retrieval of information.\\n\\nYou have also mentioned that Sam is the founder of a company called Daimon. I'm not familiar with Daimon, but I'm always interested in learning about new companies. What does Daimon do?\""
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Sam?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOplxTeNXfxmmaGgbaEUeNp",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
