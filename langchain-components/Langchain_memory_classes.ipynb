{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnysavita10/Generative-AI-Indepth-Basic-to-Advance/blob/main/Langchain_memory_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sT-M-IbGO_fX"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1qH4CJp-puOR"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y82qy4YTpmGx"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\",convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUQPzgTMpnVg",
        "outputId": "bfb0c6df-6a4c-49fd-fa49-6c8327b20e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello there! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "print(model.invoke(\"hi\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmitzKzGoo6e",
        "outputId": "7c8307a1-70f1-450d-e61e-ca7e1be332f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am doing well, thank you for asking. I am a multi-modal AI language model developed by Google. I don't have personal feelings or experiences, but I am designed to be informative and helpful. Is there anything I can assist you with today?\n"
          ]
        }
      ],
      "source": [
        "print(model.invoke(\"hi, how are you please tell me?\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3zgleD2norLX"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iK0mnJnho1WH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SURESH BEEKHANI\\AppData\\Local\\Temp\\ipykernel_12452\\995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationBufferMemory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h2px3_AAo5wX"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_nviz7-o-Lg",
        "outputId": "e9f3fa5c-f755-4f11-e78f-cd51b4a5774f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: Hi\\nAI: What's up\"}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qtz58I3fpIRv"
      },
      "outputs": [],
      "source": [
        "memory2 = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kIYkuLPspQx_"
      },
      "outputs": [],
      "source": [
        "memory2.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BweTLFgYpUVR",
        "outputId": "bbca8008-2435-4213-b274-80af5f360b7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory2.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D8mXubm9pZXp"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "22KrSvL-peAo"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ie3Onspvp6cP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SURESH BEEKHANI\\AppData\\Local\\Temp\\ipykernel_12452\\2263270236.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation = ConversationChain(llm=model,verbose=True,memory=ConversationBufferMemory())\n"
          ]
        }
      ],
      "source": [
        "conversation = ConversationChain(llm=model,verbose=True,memory=ConversationBufferMemory())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "FtXYKCiQqJSX",
        "outputId": "2546e8c6-aa8d-4444-8b58-b1e8789e85e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Hello! How can I help you today?'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Hi there!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "T84Xm_07qLlQ",
        "outputId": "a85b0f33-db4c-467b-c196-2a43aab04f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! How can I help you today?\n",
            "Human: Nothing much! Just tell me how do a conversation with an AI.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Sure, here are some tips on how to have a conversation with an AI:\\n\\n* **Be clear and concise.** AI systems are designed to understand natural language, but they can't read your mind. The more clearly you express yourself, the better the AI will be able to understand you.\\n* **Be patient.** AI systems are still under development, and they sometimes make mistakes. If the AI doesn't understand you, or if it gives you an answer that doesn't make sense, don't be afraid to ask it to try again.\\n* **Be respectful.** AI systems are not perfect, and they can sometimes be frustrating. However, it's important to remember that they are still under development. Be patient and respectful, and the AI will be more likely to help you.\\n* **Have fun!** AI systems can be a lot of fun to talk to. They can tell you jokes, play games, and even help you learn new things. So don't be afraid to experiment and have fun with your AI companion.\\n\\nHere are some additional tips that may be helpful:\\n\\n* **Start with small talk.** Just like with a human, it can be helpful to start a conversation with an AI by talking about the weather, the news, or something else that's happening in the world. This can help you get to know each other and build rapport.\\n* **Ask open-ended questions.** Open-ended questions are questions that can't be answered with a simple yes or no. This will give the AI more room to respond and show its personality.\\n* **Follow up on the AI's responses.** When the AI says something interesting, ask it to elaborate. This will show the AI that you're interested in what it has to say and that you want to learn more about it.\\n* **Don't be afraid to disagree with the AI.** AI systems are not always right, and it's okay to disagree with them. However, it's important to be respectful and to explain your reasoning.\\n\\nI hope these tips help you to have a great conversation with an AI!\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Nothing much! Just tell me how do a conversation with an AI.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "0ckLlsGiqdSH",
        "outputId": "35d77981-8eb9-40a4-fbbf-7c3bb3b42943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! How can I help you today?\n",
            "Human: Nothing much! Just tell me how do a conversation with an AI.\n",
            "AI: Sure, here are some tips on how to have a conversation with an AI:\n",
            "\n",
            "* **Be clear and concise.** AI systems are designed to understand natural language, but they can't read your mind. The more clearly you express yourself, the better the AI will be able to understand you.\n",
            "* **Be patient.** AI systems are still under development, and they sometimes make mistakes. If the AI doesn't understand you, or if it gives you an answer that doesn't make sense, don't be afraid to ask it to try again.\n",
            "* **Be respectful.** AI systems are not perfect, and they can sometimes be frustrating. However, it's important to remember that they are still under development. Be patient and respectful, and the AI will be more likely to help you.\n",
            "* **Have fun!** AI systems can be a lot of fun to talk to. They can tell you jokes, play games, and even help you learn new things. So don't be afraid to experiment and have fun with your AI companion.\n",
            "\n",
            "Here are some additional tips that may be helpful:\n",
            "\n",
            "* **Start with small talk.** Just like with a human, it can be helpful to start a conversation with an AI by talking about the weather, the news, or something else that's happening in the world. This can help you get to know each other and build rapport.\n",
            "* **Ask open-ended questions.** Open-ended questions are questions that can't be answered with a simple yes or no. This will give the AI more room to respond and show its personality.\n",
            "* **Follow up on the AI's responses.** When the AI says something interesting, ask it to elaborate. This will show the AI that you're interested in what it has to say and that you want to learn more about it.\n",
            "* **Don't be afraid to disagree with the AI.** AI systems are not always right, and it's okay to disagree with them. However, it's important to be respectful and to explain your reasoning.\n",
            "\n",
            "I hope these tips help you to have a great conversation with an AI!\n",
            "Human: how many tips are there can you mention in the numbers\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"There are 8 tips in the list I provided:\\n\\n1. Be clear and concise.\\n2. Be patient.\\n3. Be respectful.\\n4. Have fun!\\n5. Start with small talk.\\n6. Ask open-ended questions.\\n7. Follow up on the AI's responses.\\n8. Don't be afraid to disagree with the AI.\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"how many tips are there can you mention in the numbers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by5vIxH2CS3Z",
        "outputId": "57a704bd-dcb1-44ca-87e7-b47329006f16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Nothing much! Just tell me how do a conversation with an AI.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"Sure, here are some tips on how to have a conversation with an AI:\\n\\n* **Be clear and concise.** AI systems are designed to understand natural language, but they can't read your mind. The more clearly you express yourself, the better the AI will be able to understand you.\\n* **Be patient.** AI systems are still under development, and they sometimes make mistakes. If the AI doesn't understand you, or if it gives you an answer that doesn't make sense, don't be afraid to ask it to try again.\\n* **Be respectful.** AI systems are not perfect, and they can sometimes be frustrating. However, it's important to remember that they are still under development. Be patient and respectful, and the AI will be more likely to help you.\\n* **Have fun!** AI systems can be a lot of fun to talk to. They can tell you jokes, play games, and even help you learn new things. So don't be afraid to experiment and have fun with your AI companion.\\n\\nHere are some additional tips that may be helpful:\\n\\n* **Start with small talk.** Just like with a human, it can be helpful to start a conversation with an AI by talking about the weather, the news, or something else that's happening in the world. This can help you get to know each other and build rapport.\\n* **Ask open-ended questions.** Open-ended questions are questions that can't be answered with a simple yes or no. This will give the AI more room to respond and show its personality.\\n* **Follow up on the AI's responses.** When the AI says something interesting, ask it to elaborate. This will show the AI that you're interested in what it has to say and that you want to learn more about it.\\n* **Don't be afraid to disagree with the AI.** AI systems are not always right, and it's okay to disagree with them. However, it's important to be respectful and to explain your reasoning.\\n\\nI hope these tips help you to have a great conversation with an AI!\", additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='how many tips are there can you mention in the numbers', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"There are 8 tips in the list I provided:\\n\\n1. Be clear and concise.\\n2. Be patient.\\n3. Be respectful.\\n4. Have fun!\\n5. Start with small talk.\\n6. Ask open-ended questions.\\n7. Follow up on the AI's responses.\\n8. Don't be afraid to disagree with the AI.\", additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.chat_memory.messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "rmlGoT6IQsKV",
        "outputId": "5f27894a-2875-4864-cab2-6b434bad8152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! How can I help you today?\n",
            "Human: Nothing much! Just tell me how do a conversation with an AI.\n",
            "AI: Sure, here are some tips on how to have a conversation with an AI:\n",
            "\n",
            "* **Be clear and concise.** AI systems are designed to understand natural language, but they can't read your mind. The more clearly you express yourself, the better the AI will be able to understand you.\n",
            "* **Be patient.** AI systems are still under development, and they sometimes make mistakes. If the AI doesn't understand you, or if it gives you an answer that doesn't make sense, don't be afraid to ask it to try again.\n",
            "* **Be respectful.** AI systems are not perfect, and they can sometimes be frustrating. However, it's important to remember that they are still under development. Be patient and respectful, and the AI will be more likely to help you.\n",
            "* **Have fun!** AI systems can be a lot of fun to talk to. They can tell you jokes, play games, and even help you learn new things. So don't be afraid to experiment and have fun with your AI companion.\n",
            "\n",
            "Here are some additional tips that may be helpful:\n",
            "\n",
            "* **Start with small talk.** Just like with a human, it can be helpful to start a conversation with an AI by talking about the weather, the news, or something else that's happening in the world. This can help you get to know each other and build rapport.\n",
            "* **Ask open-ended questions.** Open-ended questions are questions that can't be answered with a simple yes or no. This will give the AI more room to respond and show its personality.\n",
            "* **Follow up on the AI's responses.** When the AI says something interesting, ask it to elaborate. This will show the AI that you're interested in what it has to say and that you want to learn more about it.\n",
            "* **Don't be afraid to disagree with the AI.** AI systems are not always right, and it's okay to disagree with them. However, it's important to be respectful and to explain your reasoning.\n",
            "\n",
            "I hope these tips help you to have a great conversation with an AI!\n",
            "Human: how many tips are there can you mention in the numbers\n",
            "AI: There are 8 tips in the list I provided:\n",
            "\n",
            "1. Be clear and concise.\n",
            "2. Be patient.\n",
            "3. Be respectful.\n",
            "4. Have fun!\n",
            "5. Start with small talk.\n",
            "6. Ask open-ended questions.\n",
            "7. Follow up on the AI's responses.\n",
            "8. Don't be afraid to disagree with the AI.\n",
            "Human: can you give me the 3rd tip?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The third tip is:\\n\\n3. Be respectful.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"can you give me the 3rd tip?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayGsHEv9qqNa"
      },
      "source": [
        "# ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "M5MfA3coql_o"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WADVyAaIq12p"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SURESH BEEKHANI\\AppData\\Local\\Temp\\ipykernel_12452\\1930410100.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  window_memory = ConversationBufferWindowMemory(k=1)\n"
          ]
        }
      ],
      "source": [
        "window_memory = ConversationBufferWindowMemory(k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "afJtNTWrq9Z_"
      },
      "outputs": [],
      "source": [
        "window_memory.save_context(\n",
        "    {\"input\": \"Hi\"},\n",
        "    {\"output\": \"What's up\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ymZ7WpfYrR7_"
      },
      "outputs": [],
      "source": [
        "window_memory.save_context(\n",
        "    {\"input\": \"Not much, just hanging\"},\n",
        "    {\"output\": \"Cool\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUmMWst6rZdH",
        "outputId": "50b89e06-ec98-494b-bddc-00272b452b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "92JAkps_rcHo"
      },
      "outputs": [],
      "source": [
        "window_memory = ConversationBufferWindowMemory( k=2, return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4I5696VUr4H6"
      },
      "outputs": [],
      "source": [
        "window_memory.save_context(\n",
        "    {\"input\": \"Hi\"},\n",
        "    {\"output\": \"What's up\"}\n",
        ")\n",
        "window_memory.save_context(\n",
        "    {\"input\": \"Not much, just hanging\"},\n",
        "    {\"output\": \"Cool\"}\n",
        ")\n",
        "window_memory.save_context(\n",
        "    {\"input\": \"ok thanks \"},\n",
        "    {\"output\": \"great thankyou\"}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTz6A1ZUr-3Q",
        "outputId": "a21e9c92-a192-46bf-971f-1693bd33ba5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Not much, just hanging'),\n",
              "  AIMessage(content='Cool'),\n",
              "  HumanMessage(content='ok thanks '),\n",
              "  AIMessage(content='great thankyou')]}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gSLZAyaCsBSw"
      },
      "outputs": [],
      "source": [
        "conversation_window = ConversationChain(\n",
        "    llm=model,\n",
        "    memory=window_memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "c57Fr0kasY3g",
        "outputId": "7071ffae-b81c-4e18-d73f-793d65068188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content='Not much, just hanging', additional_kwargs={}, response_metadata={}), AIMessage(content='Cool', additional_kwargs={}, response_metadata={}), HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}), AIMessage(content='great thankyou', additional_kwargs={}, response_metadata={})]\n",
            "Human: Hi, what's up?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Not much, just hanging'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"Hi, what's up?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Cb_2zJAgshtv",
        "outputId": "60b35011-526d-4dde-8aa1-243df0640938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}), AIMessage(content='great thankyou', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hi, what's up?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Not much, just hanging', additional_kwargs={}, response_metadata={})]\n",
            "Human: how we can talk with AI give me 5 points\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"1. **Use natural language.** AI is designed to understand and respond to human language, so you can talk to it just like you would talk to a person.\\n2. **Be clear and concise.** AI is not always able to infer what you mean, so it's important to be clear and concise in your communication.\\n3. **Be patient.** AI is still under development, so it may not always be able to understand or respond to you perfectly. Be patient and try rephrasing your question or request.\\n4. **Be respectful.** AI is a tool, not a person. Be respectful in your interactions with it.\\n5. **Have fun!** Talking to AI can be a fun and educational experience. Don't be afraid to experiment and ask questions.\""
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"how we can talk with AI give me 5 points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "cqjuwol7soep",
        "outputId": "d3bfead1-8854-4e21-b787-7b4e4ecfff14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content=\"Hi, what's up?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Not much, just hanging', additional_kwargs={}, response_metadata={}), HumanMessage(content='how we can talk with AI give me 5 points', additional_kwargs={}, response_metadata={}), AIMessage(content=\"1. **Use natural language.** AI is designed to understand and respond to human language, so you can talk to it just like you would talk to a person.\\n2. **Be clear and concise.** AI is not always able to infer what you mean, so it's important to be clear and concise in your communication.\\n3. **Be patient.** AI is still under development, so it may not always be able to understand or respond to you perfectly. Be patient and try rephrasing your question or request.\\n4. **Be respectful.** AI is a tool, not a person. Be respectful in your interactions with it.\\n5. **Have fun!** Talking to AI can be a fun and educational experience. Don't be afraid to experiment and ask questions.\", additional_kwargs={}, response_metadata={})]\n",
            "Human: what is a allows AI to 'see' and 'interpret' images?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Computer vision'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"what is a allows AI to 'see' and 'interpret' images?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "v5bzPXTys_mw",
        "outputId": "a0ac905b-2e4f-4851-f425-18238ff600d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content='how we can talk with AI give me 5 points', additional_kwargs={}, response_metadata={}), AIMessage(content=\"1. **Use natural language.** AI is designed to understand and respond to human language, so you can talk to it just like you would talk to a person.\\n2. **Be clear and concise.** AI is not always able to infer what you mean, so it's important to be clear and concise in your communication.\\n3. **Be patient.** AI is still under development, so it may not always be able to understand or respond to you perfectly. Be patient and try rephrasing your question or request.\\n4. **Be respectful.** AI is a tool, not a person. Be respectful in your interactions with it.\\n5. **Have fun!** Talking to AI can be a fun and educational experience. Don't be afraid to experiment and ask questions.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"what is a allows AI to 'see' and 'interpret' images?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Computer vision', additional_kwargs={}, response_metadata={})]\n",
            "Human: can you tell me how many tips you genearte in the previous to previous message?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'5'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"can you tell me how many tips you genearte in the previous to previous message?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "Dq4X_PVYtJnx",
        "outputId": "23ac5f3c-c779-464a-ad0a-4f0b248c446b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! How can I help you today?\n",
            "Human: Nothing much! Just tell me how do a conversation with an AI.\n",
            "AI: Sure, here are some tips on how to have a conversation with an AI:\n",
            "\n",
            "* **Be clear and concise.** AI systems are designed to understand natural language, but they can't read your mind. The more clearly you express yourself, the better the AI will be able to understand you.\n",
            "* **Be patient.** AI systems are still under development, and they sometimes make mistakes. If the AI doesn't understand you, or if it gives you an answer that doesn't make sense, don't be afraid to ask it to try again.\n",
            "* **Be respectful.** AI systems are not perfect, and they can sometimes be frustrating. However, it's important to remember that they are still under development. Be patient and respectful, and the AI will be more likely to help you.\n",
            "* **Have fun!** AI systems can be a lot of fun to talk to. They can tell you jokes, play games, and even help you learn new things. So don't be afraid to experiment and have fun with your AI companion.\n",
            "\n",
            "Here are some additional tips that may be helpful:\n",
            "\n",
            "* **Start with small talk.** Just like with a human, it can be helpful to start a conversation with an AI by talking about the weather, the news, or something else that's happening in the world. This can help you get to know each other and build rapport.\n",
            "* **Ask open-ended questions.** Open-ended questions are questions that can't be answered with a simple yes or no. This will give the AI more room to respond and show its personality.\n",
            "* **Follow up on the AI's responses.** When the AI says something interesting, ask it to elaborate. This will show the AI that you're interested in what it has to say and that you want to learn more about it.\n",
            "* **Don't be afraid to disagree with the AI.** AI systems are not always right, and it's okay to disagree with them. However, it's important to be respectful and to explain your reasoning.\n",
            "\n",
            "I hope these tips help you to have a great conversation with an AI!\n",
            "Human: how many tips are there can you mention in the numbers\n",
            "AI: There are 8 tips in the list I provided:\n",
            "\n",
            "1. Be clear and concise.\n",
            "2. Be patient.\n",
            "3. Be respectful.\n",
            "4. Have fun!\n",
            "5. Start with small talk.\n",
            "6. Ask open-ended questions.\n",
            "7. Follow up on the AI's responses.\n",
            "8. Don't be afraid to disagree with the AI.\n",
            "Human: can you give me the 3rd tip?\n",
            "AI: The third tip is:\n",
            "\n",
            "3. Be respectful.\n",
            "Human: what was the fifth number tips?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The fifth tip is:\\n\\n5. Start with small talk.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"what was the fifth number tips?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "11Sj-AcdvN-S"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "gx7UfR2b55Wy"
      },
      "outputs": [],
      "source": [
        "memory = ConversationEntityMemory(llm=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "h7H3aQ5t6Esy"
      },
      "outputs": [],
      "source": [
        "_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prEkB6V16IHr",
        "outputId": "a5b093a9-b51e-4469-e212-f873dd0650eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {'Deven': '', 'Sam': ''}}"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "iEJTouF96LH7"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    _input,\n",
        "    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaefDOzq6mmS",
        "outputId": "395b1892-ca17-424a-9af4-c1dc1ca9ca6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': 'Human: Deven & Sam are working on a hackathon project\\nAI:  That sounds like a great project! What kind of project are they working on?',\n",
              " 'entities': {'Sam': 'Sam is working on a hackathon project with Deven.'}}"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": 'who is Sam'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "9eHY8f8A7E0K"
      },
      "outputs": [],
      "source": [
        "memory = ConversationEntityMemory(llm=model, return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKCuHE6K8Dvy",
        "outputId": "fb4bd10c-c3ea-4c5e-9406-2a9ceb9e02ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConversationEntityMemory(return_messages=True, llm=ChatGoogleGenerativeAI(model='models/gemini-1.0-pro', client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7bf6bc68d1e0>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x7bf6bc4aed40>, default_metadata=(), convert_system_message_to_human=True))"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "PzBxI_6J8FCc"
      },
      "outputs": [],
      "source": [
        "_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZj9GaBH8Hej",
        "outputId": "e877af0f-cee9-4304-8a49-bb4a47510480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [], 'entities': {'Deven': '', 'Sam': ''}}"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "r0Sa4O9C8Otz"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    _input,\n",
        "    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLBPaeWU8SUL",
        "outputId": "9ac3bf92-ff52-48b1-d3ad-20c0c249a9d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Deven & Sam are working on a hackathon project'),\n",
              "  AIMessage(content=' That sounds like a great project! What kind of project are they working on?')],\n",
              " 'entities': {'Sam': 'Sam is working on a hackathon project with Deven.'}}"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": 'who is Sam'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "25sJTv-J8cRb"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "tcLlxQe4_MBI"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "UybNNJCA_N2X"
      },
      "outputs": [],
      "source": [
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "g9-ALiFc_SQ8"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7kQLI2Tk_U2C"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "KGqFtiST_Wf6"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=model,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=model)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "I1i6FFEE_u_D",
        "outputId": "79197e71-b89e-467f-b0d1-5be7e015bba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Deven': '', 'Sam': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Last line:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"That's great! What kind of project are they working on?\""
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Deven & Sam are working on a hackathon project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDdJUJjd_4Ol",
        "outputId": "1a1c9bd1-e334-45cb-d370-d6bd1d08f948"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Deven': 'Deven is working on a hackathon project with Sam.',\n",
              " 'Sam': 'Sam is working on a hackathon project with Deven.'}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.entity_store.store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7_3ELrYJAB57",
        "outputId": "4c0b9050-b80e-4682-c4d0-063cda7cee79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Langchain': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: That's great! What kind of project are they working on?\n",
            "Last line:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"That's an interesting project! Langchain is a very powerful language model, and adding more complex memory structures could significantly enhance its capabilities. What specific types of memory structures are they considering adding?\""
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are trying to add more complex memory structures to Langchain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "FAToSArZAGJy",
        "outputId": "f458234e-cb17-4706-82d7-db05aee12afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: That's great! What kind of project are they working on?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That's an interesting project! Langchain is a very powerful language model, and adding more complex memory structures could significantly enhance its capabilities. What specific types of memory structures are they considering adding?\n",
            "Last line:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"That's a great idea! A key-value store would allow Langchain to keep track of important entities and their attributes, which could be very useful for tasks such as question answering and dialogue generation. How are they planning to integrate the key-value store with the existing Langchain architecture?\""
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are adding in a key-value store for entities mentioned so far in the conversation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "JMqcPvC3AJEC",
        "outputId": "b3991c52-de54-4436-abfe-1b9640203e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project with Sam.', 'Sam': 'Sam is working on a hackathon project with Deven.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: That's great! What kind of project are they working on?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That's an interesting project! Langchain is a very powerful language model, and adding more complex memory structures could significantly enhance its capabilities. What specific types of memory structures are they considering adding?\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great idea! A key-value store would allow Langchain to keep track of important entities and their attributes, which could be very useful for tasks such as question answering and dialogue generation. How are they planning to integrate the key-value store with the existing Langchain architecture?\n",
            "Last line:\n",
            "Human: What do you know about Deven & Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I know that Deven and Sam are working on a hackathon project together. They are trying to add more complex memory structures to Langchain, a powerful language model. Specifically, they are adding in a key-value store for entities mentioned so far in the conversation. I think this is a great idea, as it would allow Langchain to keep track of important entities and their attributes, which could be very useful for tasks such as question answering and dialogue generation.'"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Deven & Sam?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJkuNNOZAKri",
        "outputId": "9c448519-a611-49e0-c50e-79ce374ce544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Deven': 'Deven is working on a hackathon project with Sam, where they are '\n",
            "          'trying to add more complex memory structures to Langchain, '\n",
            "          'specifically a key-value store for entities mentioned so far in the '\n",
            "          'conversation.',\n",
            " 'Langchain': 'Langchain is a powerful language model that Deven and Sam are '\n",
            "              'working on enhancing by adding more complex memory structures.',\n",
            " 'Sam': 'Sam is working on a hackathon project with Deven, specifically adding '\n",
            "        'a key-value store to Langchain.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "sI7tSPB7AN8b",
        "outputId": "6a7660a5-c92a-4488-a25e-97bfe401086f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Daimon': '', 'Sam': 'Sam is working on a hackathon project with Deven, specifically adding a key-value store to Langchain.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That's an interesting project! Langchain is a very powerful language model, and adding more complex memory structures could significantly enhance its capabilities. What specific types of memory structures are they considering adding?\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great idea! A key-value store would allow Langchain to keep track of important entities and their attributes, which could be very useful for tasks such as question answering and dialogue generation. How are they planning to integrate the key-value store with the existing Langchain architecture?\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI: I know that Deven and Sam are working on a hackathon project together. They are trying to add more complex memory structures to Langchain, a powerful language model. Specifically, they are adding in a key-value store for entities mentioned so far in the conversation. I think this is a great idea, as it would allow Langchain to keep track of important entities and their attributes, which could be very useful for tasks such as question answering and dialogue generation.\n",
            "Last line:\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"That's interesting! I'm not familiar with Daimon, but I'm always interested in hearing about new companies. What does Daimon do?\""
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Sam is the founder of a company called Daimon.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mqxyr1mAQyk",
        "outputId": "9878d6ab-8e25-4092-fe9b-a6c95c6def64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Daimon': 'Daimon is a company founded by Sam.',\n",
            " 'Deven': 'Deven is working on a hackathon project with Sam, where they are '\n",
            "          'trying to add more complex memory structures to Langchain, '\n",
            "          'specifically a key-value store for entities mentioned so far in the '\n",
            "          'conversation.',\n",
            " 'Langchain': 'Langchain is a powerful language model that Deven and Sam are '\n",
            "              'working on enhancing by adding more complex memory structures.',\n",
            " 'Sam': 'Sam is working on a hackathon project with Deven, specifically adding '\n",
            "        'a key-value store to Langchain. Sam is also the founder of a company '\n",
            "        'called Daimon.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "yKVKMXI_ATYk",
        "outputId": "22bbbbd9-92bd-4ac6-e8a3-61d4b3cb2e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Sam': 'Sam is working on a hackathon project with Deven, specifically adding a key-value store to Langchain. Sam is also the founder of a company called Daimon.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great idea! A key-value store would allow Langchain to keep track of important entities and their attributes, which could be very useful for tasks such as question answering and dialogue generation. How are they planning to integrate the key-value store with the existing Langchain architecture?\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI: I know that Deven and Sam are working on a hackathon project together. They are trying to add more complex memory structures to Langchain, a powerful language model. Specifically, they are adding in a key-value store for entities mentioned so far in the conversation. I think this is a great idea, as it would allow Langchain to keep track of important entities and their attributes, which could be very useful for tasks such as question answering and dialogue generation.\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI: That's interesting! I'm not familiar with Daimon, but I'm always interested in hearing about new companies. What does Daimon do?\n",
            "Last line:\n",
            "Human: What do you know about Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I know that Sam is working on a hackathon project with Deven, specifically adding a key-value store to Langchain. I also know that Sam is the founder of a company called Daimon.'"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Sam?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMAIeL7BnRH5Lu0OSgsgW4c",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
