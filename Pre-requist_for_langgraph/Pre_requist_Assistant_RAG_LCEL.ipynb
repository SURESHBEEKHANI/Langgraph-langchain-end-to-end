{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"what is AI \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Artificial Intelligence (AI)**\n",
      "\n",
      "Artificial Intelligence refers to the simulation of human intelligence processes by machines, particularly computer systems. It encompasses a wide range of techniques and approaches aimed at enabling machines to perform tasks that typically require human intelligence, such as:\n",
      "\n",
      "* **Learning and Adaptation:** AI systems can learn from data, identify patterns, and adapt their behavior based on new information.\n",
      "* **Reasoning and Problem-Solving:** They can analyze complex information, draw logical inferences, and make decisions.\n",
      "* **Natural Language Processing (NLP):** AI systems can understand, interpret, and generate human language.\n",
      "* **Computer Vision:** They can analyze and interpret visual data (e.g., images, videos).\n",
      "* **Speech Recognition and Synthesis:** They can recognize spoken words and generate synthesized speech.\n",
      "\n",
      "**Types of AI:**\n",
      "\n",
      "* **Machine Learning (ML):** AI systems that learn from data without explicit programming.\n",
      "* **Deep Learning:** A type of ML that uses artificial neural networks to learn complex patterns from data.\n",
      "* **Natural Language Processing (NLP):** AI systems that focus on understanding and generating human language.\n",
      "* **Computer Vision:** AI systems that analyze visual data to extract meaningful information.\n",
      "* **Expert Systems:** AI systems that emulate the knowledge and expertise of human professionals.\n",
      "\n",
      "**Applications of AI:**\n",
      "\n",
      "AI has found applications in numerous fields, including:\n",
      "\n",
      "* Healthcare: Diagnosis, treatment planning, drug discovery\n",
      "* Finance: Risk assessment, fraud detection, investment analysis\n",
      "* Manufacturing: Automation, quality control, predictive maintenance\n",
      "* Transportation: Autonomous vehicles, traffic management\n",
      "* Customer Service: Chatbots, virtual assistants\n",
      "* Entertainment: Gaming, personalized recommendations\n",
      "\n",
      "**Benefits of AI:**\n",
      "\n",
      "* **Enhanced Efficiency:** AI can automate tasks and increase productivity.\n",
      "* **Improved Accuracy:** AI systems can provide more accurate and consistent results.\n",
      "* **Data-Driven Insights:** AI can analyze large volumes of data to uncover patterns and insights.\n",
      "* **Personalized Experiences:** AI can tailor services and products to individual preferences.\n",
      "* **Innovation:** AI drives new products, services, and business models.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(question).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simple AI Assistant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory=RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Sureshbeekhani. How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"Hi! I'm Sureshbeekhani\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You did not provide me with your name, so I cannot tell you what it is.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"tell me what is my name?\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Sureshbeekhani\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Sureshbeekhani. How can I assist you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-2b4414ea-55fe-4279-bf76-b01ae8948087-0', usage_metadata={'input_tokens': 9, 'output_tokens': 13, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='tell me what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='You did not provide me with your name, so I cannot tell you what it is.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c0b01bd3-951e-4153-bd33-7087723dfd91-0', usage_metadata={'input_tokens': 31, 'output_tokens': 18, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}})])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RAG with LCEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('../data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "'''from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "'''\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A family of large language models developed by Meta AI\n"
     ]
    }
   ],
   "source": [
    "question =\"what is llama?\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Let's Start with Tools and Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Milvus (vector database)\n",
      "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\n",
      "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \n",
      "Use cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\n"
     ]
    }
   ],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2=YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=YIOfTrhEdEg&pp=ygULSXJmYW4gTWFsaWs%3D', 'https://www.youtube.com/watch?v=BDEiT-IJTGI&pp=ygULSXJmYW4gTWFsaWs%3D']\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.run(\"Irfan Malik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool3=TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Burning Man\\nSummary: Burning Man is a week-long large-scale desert event focused on \"community, art, self-expression, and self-reliance\" held annually in the western United States. The event\\'s name comes from its culminating ceremony: the symbolic burning of a large wooden effigy, referred to as the Man, that occurs on the penultimate night, the Saturday evening before Labor Day. Since 1990, the event has been at Black Rock City in northwestern Nevada, a temporary city erected in the Black Rock Desert about 100 miles (160 km) north-northeast of Reno. According to Burning Man co-founder Larry Harvey in 2004, the event is guided by ten stated principles: radical inclusion, gifting, decommodification, radical self-reliance, radical self-expression, communal effort, civic responsibility, leaving no trace, participation, and immediacy.\\nBurning Man features no headliners or scheduled performers; participants create all the art, activities, and events. Artwork includes experimental and interactive sculptures, buildings, performances, and art cars, among other media. These contributions are inspired by a theme chosen annually by the Burning Man Project. The event has been called \"countercultural revelry\" and described by its organizers as an \"excuse to party in the desert\". However, NPR said of Burning Man in 2019, \"Once considered an underground gathering for bohemians and free spirits of all stripes, Burning Man has since evolved into a destination for social media influencers, celebrities and the Silicon Valley elite.\"\\n\\nBurning Man originated on June 22, 1986, on Baker Beach in San Francisco as a small function organized by Larry Harvey and Jerry James, the builders of the first Man. It has since been held annually, spanning the nine days leading up to and including Labor Day. Over the event\\'s history, attendance has generally increased. In 2019, 78,850 people participated.\\nBurning Man is organized by the Burning Man Project, a nonprofit organization that, in 2013, succeeded Black Rock City LLC, a for-profit limited liability company. Black Rock City LLC was formed in 1999 to represent the event\\'s organizers and is now considered a subsidiary of the nonprofit organization. The Burning Man Project endorses multiple smaller regional events guided by the Burning Man principles in the United States and internationally.\\nThe film Stalker by Tarkovsky heavily influenced the Cacophony Society, which began in 1986 in the San Francisco Bay Area and which organized \"Zone Trips\" for participants.\\nThe first burning of a wooden, symbolic man at Black Rock Desert, Nevada, occurred on \"Zone Trip Number 4\" in 1990. This occasion evolved into an enormous annual festival of arts, music, and culture called Burning Man.\\n\\nPage: Resistance (video game series)\\nSummary: Resistance is a series of first-person shooter and third-person shooter video games developed by Insomniac Games and published by Sony Computer Entertainment for the PlayStation 3, PlayStation Portable and PlayStation Vita video game consoles. The series takes place in an alternate history 1950s, in which an alien civilization known as the Chimera have invaded and conquered Earth, expanding their armies by capturing humans and transforming them into monster-like super soldiers to fight for them. The player takes the role of one of the remaining human armed forces as they fight against the Chimera invasion. The series is noted for its use of both conventional and futuristic weaponry, reflecting Insomniac\\'s previous work on the Ratchet & Clank series.\\n\\nPage: Destroyed in Seconds\\nSummary: Destroyed in Seconds is an American television series that premiered on Discovery Channel on August 21, 2008.\\nHosted by Ron Pitts, it features video segments of various things being destroyed fairly quickly (hence, \"in seconds\") such as planes crashing, explosions, sinkholes, boats crashing, fires, race car incidents, floods, factories, etc. The nature of the show closely resembles Real TV. The show use'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({\"query\": \"What happened in the latest burning man floods\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools \n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"tool3\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SURESH BEEKHANI\\AppData\\Local\\Temp\\ipykernel_12740\\2645007812.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n"
     ]
    }
   ],
   "source": [
    "agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SURESH BEEKHANI\\AppData\\Local\\Temp\\ipykernel_12740\\3358457773.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"What is current GDP of pakistan?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: [wikipedia]\n",
      "Action Input: GDP of Pakistan\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: [wikipedia]\n",
      "Action Input: GDP of Pakistan\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: [wikipedia]\n",
      "Action Input: Economy of Pakistan\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: [wikipedia]\n",
      "Action Input: GDP of Pakistan\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: [wikipedia]\n",
      "Action Input: Economy of Pakistan\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: [wikipedia]\n",
      "Action Input: Economy of Pakistan\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: [wikipedia] is not a valid tool, try one of [wikipedia].\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[wikipedia] is not a valid tool, try one of [wikipedia].'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is current GDP of pakistan?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
